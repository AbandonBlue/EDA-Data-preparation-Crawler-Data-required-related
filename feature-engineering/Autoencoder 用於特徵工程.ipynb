{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder in Feature Engineering\n",
    "Wiki 定義\n",
    "- 也稱自動編碼器，是一種人工神經網絡，在無監督學習中用於有效編碼。自編碼的目的是對一組數據學習出一種表示（也稱表徵，編碼），通常用於降維。最近，自編碼的概念廣泛地用於數據的生成模型。自2010年以來，一些先進的人工智慧在深度學習網絡中採用了採用堆疊式稀疏自編碼。\n",
    "\n",
    "簡而言之\n",
    "- Autoencoder 是一個非監督式學習，透過Encoder 將原始資料(X) encode 成 latent vector，爾後 Decoder 根據 latent vector 轉換為預測值(X')，\n",
    "    而預測值(X')要與原始資料(X)越相遇越好。\n",
    "\n",
    "應用情景\n",
    "- 參考這篇 [Medium: 7 Applications of Auto-Encoders every Data Scientist should know](https://towardsdatascience.com/6-applications-of-auto-encoders-every-data-scientist-should-know-dc703cbc892b)\n",
    "\n",
    "**此次主要將著重在 Missing value 以及 特徵萃取的用途上。**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder in Imputing Missing value(待完成, 搭配[論文](https://www.sciencedirect.com/science/article/pii/S2405896318320949)服用)\n",
    "\n",
    "步驟\n",
    "1. 將原始資料隨機將特徵遺失\n",
    "2. 透過此資料建立Autnencoder\n",
    "3. 透過真實有缺失的資料進行預測，將值補全"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T12:15:25.110953Z",
     "start_time": "2021-12-30T12:15:25.098956Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T11:45:43.252689Z",
     "start_time": "2021-12-30T11:45:41.097156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 1s 12us/step\n",
      "(404, 13) (404,) (102, 13) (102,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
    "    path=\"boston_housing.npz\", test_split=0.2, seed=113\n",
    ")\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T11:58:50.181735Z",
     "start_time": "2021-12-30T11:58:50.171738Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T11:59:44.870993Z",
     "start_time": "2021-12-30T11:59:44.855997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.234847178400438 -3.8172503201932715\n",
      "4.135832294709217 -3.512256695833765\n"
     ]
    }
   ],
   "source": [
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "print(x_train.max(), x_train.min())\n",
    "print(x_test.max(), x_test.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder in Feature extraction\n",
    "\n",
    "步驟\n",
    "1. 透過原始資料建立一個autoencoder\n",
    "2. 透過autoencoder 中的latent vector 當作合成特徵存取\n",
    "3. 將合成特徵與原先特徵合併，送入模型訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T12:00:51.955333Z",
     "start_time": "2021-12-30T12:00:51.634741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.97517111764706"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 為了對比先建立一個簡單的model去預測\n",
    "\n",
    "rf = RandomForestRegressor().fit(x_train, y_train)\n",
    "mean_squared_error(y_test, rf.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T12:10:55.257754Z",
     "start_time": "2021-12-30T12:10:55.175417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 13)]              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               1792      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "latent_layer (Dense)         (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 13)                1677      \n",
      "=================================================================\n",
      "Total params: 24,237\n",
      "Trainable params: 24,237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 建立autoencoder, 搭配: https://blog.csdn.net/hahajinbu/article/details/77982721, 抽取中間層建立一個萃取器\n",
    "\n",
    "def get_autoencoder():\n",
    "    model_input = keras.Input(shape=(13,))\n",
    "    layer_one = layers.Dense(units=128, activation='relu')(model_input)\n",
    "    layer_two = layers.Dense(units=64, activation='relu')(layer_one)\n",
    "    latent_layer = layers.Dense(units=32, activation='relu', name='latent_layer')(layer_two)\n",
    "    layer_three = layers.Dense(units=64, activation='relu')(latent_layer)\n",
    "    layer_four = layers.Dense(units=128, activation='relu')(layer_three)\n",
    "    model_output = layers.Dense(units=13)(layer_four)\n",
    "    \n",
    "    return keras.Model(model_input, model_output)\n",
    "\n",
    "autoencoder = get_autoencoder()\n",
    "autoencoder.compile(optimizer='adam', loss='mse', metrics=['mse', 'mae'])\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T12:11:05.732695Z",
     "start_time": "2021-12-30T12:11:00.786811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 576.6544 - mse: 576.6544 - mae: 22.1719 - val_loss: 580.3072 - val_mse: 580.3072 - val_mae: 22.2927\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 485.7361 - mse: 485.7361 - mae: 19.9749 - val_loss: 364.0193 - val_mse: 364.0193 - val_mae: 16.8113\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 198.2245 - mse: 198.2245 - mae: 11.5547 - val_loss: 114.7941 - val_mse: 114.7941 - val_mae: 8.2976\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 70.3138 - mse: 70.3138 - mae: 6.2491 - val_loss: 49.1231 - val_mse: 49.1231 - val_mae: 5.4605\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 39.9628 - mse: 39.9628 - mae: 4.5581 - val_loss: 30.0234 - val_mse: 30.0234 - val_mae: 4.3544\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 25.9943 - mse: 25.9943 - mae: 3.6301 - val_loss: 27.1576 - val_mse: 27.1576 - val_mae: 4.0097\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 21.1251 - mse: 21.1251 - mae: 3.3452 - val_loss: 24.8784 - val_mse: 24.8784 - val_mae: 3.7043\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 17.7013 - mse: 17.7013 - mae: 2.9866 - val_loss: 22.7589 - val_mse: 22.7589 - val_mae: 3.5010\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 15.4154 - mse: 15.4154 - mae: 2.8197 - val_loss: 23.3083 - val_mse: 23.3083 - val_mae: 3.5021\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.6243 - mse: 13.6243 - mae: 2.6309 - val_loss: 22.7064 - val_mse: 22.7064 - val_mae: 3.3090\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.5085 - mse: 12.5085 - mae: 2.5807 - val_loss: 23.0099 - val_mse: 23.0099 - val_mae: 3.3074\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 11.4545 - mse: 11.4545 - mae: 2.4203 - val_loss: 22.6637 - val_mse: 22.6637 - val_mae: 3.1767\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.6156 - mse: 10.6156 - mae: 2.3732 - val_loss: 24.3151 - val_mse: 24.3151 - val_mae: 3.2426\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.7917 - mse: 10.7917 - mae: 2.3918 - val_loss: 22.6976 - val_mse: 22.6976 - val_mae: 3.0947\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 10.0015 - mse: 10.0015 - mae: 2.2966 - val_loss: 23.0443 - val_mse: 23.0443 - val_mae: 3.2728\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.7529 - mse: 9.7529 - mae: 2.3013 - val_loss: 23.1676 - val_mse: 23.1676 - val_mae: 3.1928\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.1564 - mse: 9.1564 - mae: 2.1974 - val_loss: 22.2704 - val_mse: 22.2704 - val_mae: 2.9988\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.1181 - mse: 9.1181 - mae: 2.2263 - val_loss: 23.6663 - val_mse: 23.6663 - val_mae: 3.2149\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.0177 - mse: 9.0177 - mae: 2.1957 - val_loss: 22.9418 - val_mse: 22.9418 - val_mae: 3.2764\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.8728 - mse: 8.8728 - mae: 2.2206 - val_loss: 22.1657 - val_mse: 22.1657 - val_mae: 3.0289\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.3490 - mse: 8.3490 - mae: 2.1125 - val_loss: 22.8155 - val_mse: 22.8155 - val_mae: 2.9680\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.9527 - mse: 7.9527 - mae: 2.0517 - val_loss: 21.9041 - val_mse: 21.9041 - val_mae: 2.9330\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.7978 - mse: 7.7978 - mae: 2.0530 - val_loss: 20.9785 - val_mse: 20.9785 - val_mae: 2.9749\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.0203 - mse: 8.0203 - mae: 2.0746 - val_loss: 22.4732 - val_mse: 22.4732 - val_mae: 3.1731\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.3851 - mse: 7.3851 - mae: 2.0051 - val_loss: 20.5884 - val_mse: 20.5884 - val_mae: 2.9027\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.5026 - mse: 7.5026 - mae: 1.9900 - val_loss: 22.5336 - val_mse: 22.5336 - val_mae: 2.9668\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.2948 - mse: 7.2948 - mae: 1.9828 - val_loss: 20.8223 - val_mse: 20.8223 - val_mae: 2.9768\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.9373 - mse: 6.9373 - mae: 1.9241 - val_loss: 20.7046 - val_mse: 20.7046 - val_mae: 2.9746\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.7115 - mse: 6.7115 - mae: 1.8862 - val_loss: 19.8679 - val_mse: 19.8679 - val_mae: 2.8317\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.1249 - mse: 7.1249 - mae: 1.9456 - val_loss: 20.6490 - val_mse: 20.6490 - val_mae: 3.0666\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.1869 - mse: 7.1869 - mae: 1.9925 - val_loss: 20.3974 - val_mse: 20.3974 - val_mae: 3.1411\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.6930 - mse: 6.6930 - mae: 1.9134 - val_loss: 18.6478 - val_mse: 18.6478 - val_mae: 2.7570\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.6341 - mse: 6.6341 - mae: 1.9024 - val_loss: 19.3313 - val_mse: 19.3313 - val_mae: 2.9411\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.6254 - mse: 6.6254 - mae: 1.8928 - val_loss: 21.3839 - val_mse: 21.3839 - val_mae: 3.2099\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.3998 - mse: 6.3998 - mae: 1.8597 - val_loss: 18.6517 - val_mse: 18.6517 - val_mae: 2.8983\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.2869 - mse: 6.2869 - mae: 1.8532 - val_loss: 19.1159 - val_mse: 19.1159 - val_mae: 2.8925\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.5856 - mse: 6.5856 - mae: 1.8519 - val_loss: 20.1211 - val_mse: 20.1211 - val_mae: 3.0699\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.3711 - mse: 6.3711 - mae: 1.8540 - val_loss: 17.9615 - val_mse: 17.9615 - val_mae: 2.8351\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.8887 - mse: 5.8887 - mae: 1.7409 - val_loss: 18.2570 - val_mse: 18.2570 - val_mae: 2.8903\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.2262 - mse: 5.2262 - mae: 1.6852 - val_loss: 18.2862 - val_mse: 18.2862 - val_mae: 2.6727\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.1775 - mse: 5.1775 - mae: 1.6381 - val_loss: 17.9947 - val_mse: 17.9947 - val_mae: 2.7530\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.3672 - mse: 5.3672 - mae: 1.6710 - val_loss: 18.0150 - val_mse: 18.0150 - val_mae: 2.7547\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.2410 - mse: 5.2410 - mae: 1.6777 - val_loss: 16.6996 - val_mse: 16.6996 - val_mae: 2.6408\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.3557 - mse: 5.3557 - mae: 1.6876 - val_loss: 16.8454 - val_mse: 16.8454 - val_mae: 2.6775\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.8937 - mse: 4.8937 - mae: 1.5931 - val_loss: 16.6495 - val_mse: 16.6495 - val_mae: 2.5925\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.6767 - mse: 4.6767 - mae: 1.5636 - val_loss: 16.3716 - val_mse: 16.3716 - val_mae: 2.5542\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.8441 - mse: 4.8441 - mae: 1.6254 - val_loss: 16.7627 - val_mse: 16.7627 - val_mae: 2.6332\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.8713 - mse: 4.8713 - mae: 1.6257 - val_loss: 15.4604 - val_mse: 15.4604 - val_mae: 2.4894\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.9132 - mse: 4.9132 - mae: 1.5974 - val_loss: 17.9983 - val_mse: 17.9983 - val_mae: 2.7507\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step - loss: 5.0034 - mse: 5.0034 - mae: 1.6436 - val_loss: 15.6243 - val_mse: 15.6243 - val_mae: 2.5231\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.6303 - mse: 4.6303 - mae: 1.5671 - val_loss: 14.5021 - val_mse: 14.5021 - val_mae: 2.4609\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.3820 - mse: 4.3820 - mae: 1.5126 - val_loss: 16.6920 - val_mse: 16.6920 - val_mae: 2.6434\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.6683 - mse: 4.6683 - mae: 1.5484 - val_loss: 15.7768 - val_mse: 15.7768 - val_mae: 2.7534\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.7901 - mse: 4.7901 - mae: 1.6114 - val_loss: 16.2903 - val_mse: 16.2903 - val_mae: 2.7637\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.6144 - mse: 4.6144 - mae: 1.6347 - val_loss: 15.8037 - val_mse: 15.8037 - val_mae: 2.7037\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.6277 - mse: 4.6277 - mae: 1.5768 - val_loss: 15.1425 - val_mse: 15.1425 - val_mae: 2.7522\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.0809 - mse: 4.0809 - mae: 1.5031 - val_loss: 15.0501 - val_mse: 15.0501 - val_mae: 2.5911\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.9193 - mse: 3.9193 - mae: 1.4347 - val_loss: 14.1390 - val_mse: 14.1390 - val_mae: 2.4841\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.8074 - mse: 3.8074 - mae: 1.3888 - val_loss: 13.5121 - val_mse: 13.5121 - val_mae: 2.4192\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.6766 - mse: 3.6766 - mae: 1.3874 - val_loss: 13.9269 - val_mse: 13.9269 - val_mae: 2.5142\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.6512 - mse: 3.6512 - mae: 1.3729 - val_loss: 14.0703 - val_mse: 14.0703 - val_mae: 2.4710\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.0801 - mse: 4.0801 - mae: 1.4808 - val_loss: 13.7729 - val_mse: 13.7729 - val_mae: 2.4682\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.6613 - mse: 3.6613 - mae: 1.4174 - val_loss: 13.4115 - val_mse: 13.4115 - val_mae: 2.3856\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.1159 - mse: 4.1159 - mae: 1.5037 - val_loss: 13.5841 - val_mse: 13.5841 - val_mae: 2.5153\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.2998 - mse: 4.2998 - mae: 1.4800 - val_loss: 13.8222 - val_mse: 13.8222 - val_mae: 2.5797\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.4492 - mse: 3.4492 - mae: 1.3614 - val_loss: 13.7122 - val_mse: 13.7122 - val_mae: 2.4324\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.5963 - mse: 3.5963 - mae: 1.3835 - val_loss: 12.3420 - val_mse: 12.3420 - val_mae: 2.3791\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.6200 - mse: 3.6200 - mae: 1.4103 - val_loss: 12.6137 - val_mse: 12.6137 - val_mae: 2.4282\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.1633 - mse: 3.1633 - mae: 1.2736 - val_loss: 12.9117 - val_mse: 12.9117 - val_mae: 2.4098\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.0891 - mse: 3.0891 - mae: 1.2633 - val_loss: 12.3325 - val_mse: 12.3325 - val_mae: 2.3854\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.1398 - mse: 3.1398 - mae: 1.2968 - val_loss: 13.0105 - val_mse: 13.0105 - val_mae: 2.4345\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.1352 - mse: 3.1352 - mae: 1.2932 - val_loss: 12.3161 - val_mse: 12.3161 - val_mae: 2.4494\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.9043 - mse: 2.9043 - mae: 1.2265 - val_loss: 12.3147 - val_mse: 12.3147 - val_mae: 2.4251\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.9614 - mse: 2.9614 - mae: 1.2766 - val_loss: 12.4433 - val_mse: 12.4433 - val_mae: 2.4227\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.1401 - mse: 3.1401 - mae: 1.2988 - val_loss: 12.5822 - val_mse: 12.5822 - val_mae: 2.4675\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.1837 - mse: 3.1837 - mae: 1.3019 - val_loss: 12.7574 - val_mse: 12.7574 - val_mae: 2.4313\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.2486 - mse: 3.2486 - mae: 1.3312 - val_loss: 11.1878 - val_mse: 11.1878 - val_mae: 2.3007\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.0834 - mse: 3.0834 - mae: 1.2957 - val_loss: 12.3244 - val_mse: 12.3244 - val_mae: 2.4307\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.7172 - mse: 2.7172 - mae: 1.2048 - val_loss: 11.7499 - val_mse: 11.7499 - val_mae: 2.3851\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.6791 - mse: 2.6791 - mae: 1.1946 - val_loss: 12.5431 - val_mse: 12.5431 - val_mae: 2.4611\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.6961 - mse: 2.6961 - mae: 1.2099 - val_loss: 12.1093 - val_mse: 12.1093 - val_mae: 2.4013\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.7562 - mse: 2.7562 - mae: 1.2486 - val_loss: 11.8338 - val_mse: 11.8338 - val_mae: 2.3897\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.6814 - mse: 2.6814 - mae: 1.1899 - val_loss: 11.8231 - val_mse: 11.8231 - val_mae: 2.3960\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.3906 - mse: 2.3906 - mae: 1.1187 - val_loss: 11.9435 - val_mse: 11.9435 - val_mae: 2.4095\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.3401 - mse: 2.3401 - mae: 1.1032 - val_loss: 11.3915 - val_mse: 11.3915 - val_mae: 2.3613\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.3393 - mse: 2.3393 - mae: 1.1024 - val_loss: 11.6865 - val_mse: 11.6865 - val_mae: 2.3932\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.6469 - mse: 2.6469 - mae: 1.1850 - val_loss: 12.3118 - val_mse: 12.3118 - val_mae: 2.5005\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.7200 - mse: 2.7200 - mae: 1.1908 - val_loss: 12.2739 - val_mse: 12.2739 - val_mae: 2.4794\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.4016 - mse: 2.4016 - mae: 1.1269 - val_loss: 11.2864 - val_mse: 11.2864 - val_mae: 2.3969\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.4146 - mse: 2.4146 - mae: 1.1336 - val_loss: 12.2749 - val_mse: 12.2749 - val_mae: 2.5054\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.4634 - mse: 2.4634 - mae: 1.1604 - val_loss: 11.5815 - val_mse: 11.5815 - val_mae: 2.4406\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.2374 - mse: 2.2374 - mae: 1.0912 - val_loss: 11.4061 - val_mse: 11.4061 - val_mae: 2.3482\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.1574 - mse: 2.1574 - mae: 1.0742 - val_loss: 11.1090 - val_mse: 11.1090 - val_mae: 2.3632\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.0809 - mse: 2.0809 - mae: 1.0531 - val_loss: 11.8357 - val_mse: 11.8357 - val_mae: 2.4276\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.2549 - mse: 2.2549 - mae: 1.0886 - val_loss: 11.3376 - val_mse: 11.3376 - val_mae: 2.3965\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.8186 - mse: 2.8186 - mae: 1.2883 - val_loss: 11.4352 - val_mse: 11.4352 - val_mae: 2.4010\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.5179 - mse: 2.5179 - mae: 1.1963 - val_loss: 11.3151 - val_mse: 11.3151 - val_mae: 2.3685\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.6480 - mse: 2.6480 - mae: 1.2288 - val_loss: 11.5410 - val_mse: 11.5410 - val_mae: 2.4474\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step - loss: 2.0852 - mse: 2.0852 - mae: 1.0787 - val_loss: 10.5310 - val_mse: 10.5310 - val_mae: 2.2897\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.9484 - mse: 1.9484 - mae: 1.0123 - val_loss: 11.2251 - val_mse: 11.2251 - val_mae: 2.4104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x187ccb656d8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 雖然有overfitting 但先不處理，只是簡單應用\n",
    "\n",
    "autoencoder.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T12:14:59.722874Z",
     "start_time": "2021-12-30T12:14:59.547685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 32) (102, 32)\n"
     ]
    }
   ],
   "source": [
    "def get_latent_model():\n",
    "    return keras.Model(autoencoder.input, autoencoder.get_layer('latent_layer').output)\n",
    "\n",
    "latent_model = get_latent_model()\n",
    "x_train_latent_vector = latent_model.predict(x_train)\n",
    "x_test_latent_vector = latent_model.predict(x_test)\n",
    "\n",
    "print(x_train_latent_vector.shape, x_test_latent_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T12:16:25.232511Z",
     "start_time": "2021-12-30T12:16:25.218990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 45) (102, 45)\n"
     ]
    }
   ],
   "source": [
    "new_x_train = np.concatenate((x_train, x_train_latent_vector), axis=1)\n",
    "new_x_test = np.concatenate((x_test, x_test_latent_vector), axis=1)\n",
    "\n",
    "print(new_x_train.shape, new_x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T12:17:18.118465Z",
     "start_time": "2021-12-30T12:17:17.535727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.586816833333334"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 再用一次 RF\n",
    "\n",
    "new_rf = RandomForestRegressor().fit(new_x_train, y_train)\n",
    "mean_squared_error(y_test, new_rf.predict(new_x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T12:23:13.444853Z",
     "start_time": "2021-12-30T12:21:49.775308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def experimental(times=100):\n",
    "    count = 0\n",
    "    for i in range(times):\n",
    "        rf = RandomForestRegressor().fit(x_train, y_train)\n",
    "        ori_mse = mean_squared_error(y_test, rf.predict(x_test))\n",
    "        \n",
    "        new_rf = RandomForestRegressor().fit(new_x_train, y_train)\n",
    "        mse = mean_squared_error(y_test, new_rf.predict(new_x_test))\n",
    "        \n",
    "        if mse < ori_mse:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "experimental(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
